<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="scrapy," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="参考代码来自于这里，算是二次加工吧。但我其实基本上重写了所有代码，item的定义，spider的逻辑，pipline的数据处理存储等，不过论坛信息爬取的思路分析，模拟登陆及cookie传递都是受原始代码的启发而来，感谢原作者buptbill200。在腾讯的云服务器上跑过几次，基本功能能跑通，但还有不完善之处，比如帖子的主体信息处理与存储部分。">
<meta property="og:type" content="article">
<meta property="og:title" content="scrapy:爬取北邮人论坛所有帖的基本信息及正文">
<meta property="og:url" content="http://yoursite.com/2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/index.html">
<meta property="og:site_name" content="Ryder's Blog">
<meta property="og:description" content="参考代码来自于这里，算是二次加工吧。但我其实基本上重写了所有代码，item的定义，spider的逻辑，pipline的数据处理存储等，不过论坛信息爬取的思路分析，模拟登陆及cookie传递都是受原始代码的启发而来，感谢原作者buptbill200。在腾讯的云服务器上跑过几次，基本功能能跑通，但还有不完善之处，比如帖子的主体信息处理与存储部分。">
<meta property="og:image" content="http://yoursite.com/img/scrapy1.jpg">
<meta property="og:image" content="http://yoursite.com/img/scrapy-framework.png">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/1.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/2.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/3.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/4.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/5.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/section.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/articleinfo.jpg">
<meta property="og:image" content="http://yoursite.com/img/bbsSpider/articlebody.jpg">
<meta property="og:updated_time" content="2017-01-31T15:35:54.546Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="scrapy:爬取北邮人论坛所有帖的基本信息及正文">
<meta name="twitter:description" content="参考代码来自于这里，算是二次加工吧。但我其实基本上重写了所有代码，item的定义，spider的逻辑，pipline的数据处理存储等，不过论坛信息爬取的思路分析，模拟登陆及cookie传递都是受原始代码的启发而来，感谢原作者buptbill200。在腾讯的云服务器上跑过几次，基本功能能跑通，但还有不完善之处，比如帖子的主体信息处理与存储部分。">
<meta name="twitter:image" content="http://yoursite.com/img/scrapy1.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 6334502127095776000,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/"/>

  <title> scrapy:爬取北邮人论坛所有帖的基本信息及正文 | Ryder's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Ryder's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                scrapy:爬取北邮人论坛所有帖的基本信息及正文
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-01-31T00:00:00+08:00" content="2017-01-31">
              2017-01-31
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/学习/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/学习/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="/img/scrapy1.jpg" width="900" height="600" alt="scrapy1" align="center"><br>参考代码来自于<a href="https://github.com/buptbill220/bbsspider" target="_blank" rel="external">这里</a>，算是二次加工吧。但我其实基本上重写了所有代码，item的定义，spider的逻辑，pipline的数据处理存储等，不过论坛信息爬取的思路分析，模拟登陆及cookie传递都是受原始代码的启发而来，感谢原作者buptbill200。在腾讯的云服务器上跑过几次，基本功能能跑通，但还有不完善之处，比如帖子的主体信息处理与存储部分。<br><a id="more"></a></p>
<h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>爬取<a href="https://bbs.byr.cn" title="北邮人论坛" target="_blank" rel="external">北邮人论坛</a>十个主要板块的板块信息，包括子版块信息，板块的总帖数。针对每一个板块，爬取板块内的所有帖子，包括作者，上传时间，回帖数等等。并获取帖子的主体内容。以上信息均存储与Mysql中。</p>
<h1 id="环境与工具"><a href="#环境与工具" class="headerlink" title="环境与工具"></a>环境与工具</h1><ul>
<li>windows 10 64位 专业版</li>
<li>java 版本 1.8.0_111</li>
<li>Mysql 版本 5.7</li>
<li>python 版本 2.7.12（anaconda4.2 64位）</li>
<li>scrapy</li>
<li>re</li>
<li>MySQLdb</li>
<li>functools</li>
</ul>
<h1 id="scrapy基本原理"><a href="#scrapy基本原理" class="headerlink" title="scrapy基本原理"></a>scrapy基本原理</h1><p>scrapy有详细的使用文档，也有人做了翻译（<a href="http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html" title="Scrapy中文文档" target="_blank" rel="external">中文版</a>版本较低），且原理讲解中穿插有相当多的代码实例，有时间的话推荐仔细看下。以下简要介绍几个关键组件及其作用。</p>
<p><img src="/img/scrapy-framework.png" width="900" height="600" alt="scrapy-framework" align="center"></p>
<h2 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h2><h3 id="Scrapy-Engine"><a href="#Scrapy-Engine" class="headerlink" title="Scrapy Engine"></a>Scrapy Engine</h3><p>Scrapy引擎是用来控制整个系统的数据处理流程，并进行事务处理的触发。更多的详细内容可以看下面的数据处理流程。</p>
<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>调度程序从Scrapy引擎接受请求并排序列入队列，并在Scrapy引擎发出请求后返还给他们。</p>
<h3 id="Downloader"><a href="#Downloader" class="headerlink" title="Downloader"></a>Downloader</h3><p>下载器的主要职责是抓取网页并将网页内容返还给 Spiders。</p>
<h3 id="Spiders"><a href="#Spiders" class="headerlink" title="Spiders"></a>Spiders</h3><p>Spiders是由用户自己定义用来解析网页并抓取制定URL返回内容的类，每个Spider都能处理一个域名或一组域名。换句话说就是用来定义特定网站的抓取和解析规则。</p>
<p>Spider的整个抓取流程是这样的：</p>
<p>（1）首先获取第一个URL的初始请求，当请求返回后调取一个回调函数。第一个请求是通过调用start_requests()方法完成的。该方法默认从start_urls中的Url中生成请求，交由回调函数处理。当然也可以自己重写这些函数。</p>
<p>（2）回调函数解析网页响应并返回项目对象item或请求对象request的迭代。即使返回的是request，最终的处理结果也应该是可迭代的item。若是request，这些请求也将包含一个回调，交由下一个回调函数处理。如此循环。这一过程中cookie的传递，item数据的传递，由request中meta的对应参数完成，如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="keyword">yield</span> scrapy.Request(url, meta=&#123;<span class="string">'cookiejar'</span>: response.meta[<span class="string">'cookiejar'</span>],<span class="string">'item'</span>:item&#125;, headers=HEADERS, callback=self.parse)</div></pre></td></tr></table></figure>
<p>（3）在回调函数中，解析网站内容使用的是Xpath选择器，并生成解析的数据项，存储于item中。</p>
<p>（4）最后，由pipelines来处理返回的item，可以直接打印输出，存储到csv，json文件中，或存储到mysql中。</p>
<h3 id="Item-Pipeline"><a href="#Item-Pipeline" class="headerlink" title="Item Pipeline"></a>Item Pipeline</h3><p>项目管道的主要责任是负责处理从网页中抽取的item，他的主要任务是清晰、验证和存储数据。当页面被蜘蛛解析后，将被发送到项目管道，并经过几 个特定的次序处理数据。每个项目管道的组件都是有一个简单的方法组成的Python类。他们获取了项目并执行他们的方法，同时他们还需要确定的是是否需要 在项目管道中继续执行下一步或是直接丢弃掉不处理。</p>
<p>项目管道通常执行的过程有：</p>
<ol>
<li>清洗HTML数据</li>
<li>验证解析到的数据（检查项目是否包含必要的字段）</li>
<li>检查是否是重复数据（如果重复就删除）</li>
<li>将解析到的数据存储到数据库中</li>
</ol>
<h3 id="Downloader-middlewares（下载器中间件）"><a href="#Downloader-middlewares（下载器中间件）" class="headerlink" title="Downloader middlewares（下载器中间件）"></a>Downloader middlewares（下载器中间件）</h3><p>下载中间件是位于Scrapy引擎和下载器之间的钩子框架，主要是处理Scrapy引擎与下载器之间的请求及响应。它提供了一个自定义的代码的方式 来拓展Scrapy的功能。下载中间器是一个处理请求和响应的钩子框架。他是轻量级的，对Scrapy尽享全局控制的底层的系统。</p>
<h3 id="Spider-middlewares（spider中间件）"><a href="#Spider-middlewares（spider中间件）" class="headerlink" title="Spider middlewares（spider中间件）"></a>Spider middlewares（spider中间件）</h3><p>spider中间件是介于Scrapy引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛的响应输入和请求输出。它提供一个自定义代码的方式来拓展Scrapy 的功能。蛛中间件是一个挂接到Scrapy的蜘蛛处理机制的框架，你可以插入自定义的代码来处理发送给蜘蛛的请求和返回蜘蛛获取的响应内容和项目。</p>
<h3 id="Scheduler-middlewares（调度中间件）"><a href="#Scheduler-middlewares（调度中间件）" class="headerlink" title="Scheduler middlewares（调度中间件）"></a>Scheduler middlewares（调度中间件）</h3><p>调度中间件是介于Scrapy引擎和调度之间的中间件，主要工作是处从Scrapy引擎发送到调度的请求和响应。他提供了一个自定义的代码来拓展Scrapy的功能。</p>
<h1 id="网站分析"><a href="#网站分析" class="headerlink" title="网站分析"></a>网站分析</h1><h2 id="模拟登陆"><a href="#模拟登陆" class="headerlink" title="模拟登陆"></a>模拟登陆</h2><p>为了分析登陆时后台所做的操作，可以先输入错误的登陆信息，观察后台的响应，如果你也用的是chrome，按F12即可调出检测工具。</p>
<p><img src="/img/bbsSpider/1.jpg" width="900" height="600" align="center"></p>
<p>进入Network选项卡，然后输入错误登陆信息，发现有个ajax_login.json文件出现，而Headers中所传入的Form Data的id和passwd就是刚才输入的账号密码。可以确定此文件跟登陆有密切关系。</p>
<p><img src="/img/bbsSpider/2.jpg" width="900" height="900" align="center"></p>
<h2 id="传递cookie"><a href="#传递cookie" class="headerlink" title="传递cookie"></a>传递cookie</h2><p>为了保持登陆，需要传递cookie。与request的值传递类似，cookie的传递也用到了meta，具体见代码。如果想看cookie的传递信息，可在settings中设置COOKIES_DEBIG=True。</p>
<h2 id="板块相关文件与逻辑分析"><a href="#板块相关文件与逻辑分析" class="headerlink" title="板块相关文件与逻辑分析"></a>板块相关文件与逻辑分析</h2><p>既然要爬取所有帖子，首先就要有所有的板块链接。论坛的讨论区共有10个一级板块。</p>
<p><img src="/img/bbsSpider/3.jpg" width="900" height="900" align="center"></p>
<p>当打开第一个板块的“+”，会生成ajax_list.json?……文件（红框所示），打开第二个板块，对应文件的链接的sec为1</p>
<p><img src="/img/bbsSpider/4.jpg" width="900" height="900" align="center"></p>
<p>稍微熟悉些http/https的应该能分析出来，打开一级板块的“+”，后台会向ajax_list.json发起post请求，携带的信息（？后面部分）为uid和root，uid为用户名，root的形式为“sec-X”,X取值为0到9，对应第一到第十个一级板块。当然也可以不这么麻烦，直接构造出10个板块的请求链接，即修改sec-后面的数字。</p>
<p>一级板块有10个，每一个板块下可能还有类似的统领型板块（由几个小版块组成），如[北邮校园]下，[北邮教务处]之下就是具体帖子了，但[社团组织]下还能细分出很多板块。可以理解成我们想看一台电脑上10个文件夹下的所有文件内容，但这些文件下有的打开后就能看到文件，有的则是文件夹嵌套，需要打开很多次才能看到文件。至于判断一个板块否是统领型板块，这个可以通过ajax_list.json中的板块链接进行区分。</p>
<p><img src="/img/bbsSpider/5.jpg" width="900" height="900" align="center"></p>
<h1 id="正式开始"><a href="#正式开始" class="headerlink" title="正式开始"></a>正式开始</h1><h2 id="新建项目与数据库"><a href="#新建项目与数据库" class="headerlink" title="新建项目与数据库"></a>新建项目与数据库</h2><h3 id="使用scrapy-shell创建项目及其他常用命令"><a href="#使用scrapy-shell创建项目及其他常用命令" class="headerlink" title="使用scrapy shell创建项目及其他常用命令"></a>使用scrapy shell创建项目及其他常用命令</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">scrapy startproject byrbbs   # 创建项目</div><div class="line">scrapy genspider byr_section bbs.byr.cn  #创建一个爬虫，一个项目中可创建多个</div><div class="line">scrapy list #显示当前项目所包括的爬虫</div><div class="line">scrapy crawl byr_section #启动爬虫byr_section</div></pre></td></tr></table></figure>
<p>爬虫写好后，用crawl命令运行，如果你像我一样使用pycharm写的爬虫，不想要再开个shell窗口运行crawl，可以把这条命令写到一个.py文件中：</p>
<figure class="highlight vala"><table><tr><td class="code"><pre><div class="line"><span class="meta"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="meta"># command.py file</span></div><div class="line">import os</div><div class="line"></div><div class="line"><span class="meta">#如果此文件就存于项目目录，可以注释掉下面这行更改工作目录的代码</span></div><div class="line"><span class="meta"># os.chdir(r'C:\Users\chen\PycharmProjects\byrbbs') </span></div><div class="line"></div><div class="line"><span class="meta"># os.system('scrapy crawl byr_section')   # 运行爬虫byr_section</span></div><div class="line"><span class="meta"># os.system('scrapy crawl byr_article -o article_list.xml')  # 运行爬虫byr_section，并将item存到xml文件中（在没写pipline前可以先在本地存储）</span></div><div class="line"></div><div class="line">os.system(<span class="string">'scrapy crawl byr_article'</span>)</div></pre></td></tr></table></figure>
<h3 id="创建数据库表格"><a href="#创建数据库表格" class="headerlink" title="创建数据库表格"></a>创建数据库表格</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">CREATE TABLE `section` (</div><div class="line">  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,</div><div class="line">  `section_url` varchar(60) NOT NULL,</div><div class="line">  `section_name` varchar(50) NOT NULL,</div><div class="line">  `section_article_total` int(7) NOT NULL,</div><div class="line">  `top_section_name` varchar(50) NOT NULL,</div><div class="line">  `top_section_num` int(2) NOT NULL DEFAULT &apos;0&apos;,</div><div class="line">  PRIMARY KEY (`id`)</div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;</div><div class="line"></div><div class="line"></div><div class="line">create TABLE `articleinfo` (                       </div><div class="line">  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,   </div><div class="line">  `section_name` varchar(50) NOT NULL,</div><div class="line">  `article_title` varchar(80) NOT NULL,   </div><div class="line">  `article_url` varchar(80) NOT NULL,</div><div class="line">  `article_createtime` date NOT NULL,</div><div class="line">  `article_comment` int(10) unsigned NOT NULL DEFAULT &apos;0&apos;,</div><div class="line">  `article_author` varchar(50),                                            </div><div class="line">  PRIMARY KEY (`id`)                                                           </div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;</div><div class="line"></div><div class="line"></div><div class="line">CREATE TABLE `articlebody` (                       </div><div class="line">  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,   </div><div class="line">  `article_url` varchar(80) NOT NULL,</div><div class="line">  `article_content` text, </div><div class="line">  PRIMARY KEY (`id`)                                                           </div><div class="line">) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;</div></pre></td></tr></table></figure>
<h2 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h2><h3 id="文件目录结构"><a href="#文件目录结构" class="headerlink" title="文件目录结构"></a>文件目录结构</h3><figure class="highlight livecodeserver"><table><tr><td class="code"><pre><div class="line">byrbbs/   <span class="comment">#项目根目录</span></div><div class="line">  ├── byrbbs/       <span class="comment">#项目文件夹</span></div><div class="line">        ├── spiders/        <span class="comment">#爬虫程序文件夹</span></div><div class="line">        	 ├── __init__.py        <span class="comment">#</span></div><div class="line">        	 ├── byr_section.py     <span class="comment">#</span></div><div class="line">        	 ├── byr_config.py      <span class="comment">#</span></div><div class="line">        ├── <span class="keyword">item</span>.py         <span class="comment">#  </span></div><div class="line">        ├── middlewares.py  <span class="comment">#  中间件，未作更改，并未使用</span></div><div class="line">        ├── pipelines.py    <span class="comment">#  用于数据处理与存储</span></div><div class="line">        ├── settings.py     <span class="comment">#  项目配置文件，如pipline的启用，LOG的设置等等</span></div><div class="line">  ├── scrapy.cfg    <span class="comment">#自动生成，里面存有settings和deploy的配置</span></div><div class="line">  ├── .gitignore    <span class="comment">#git忽略文件，写明了哪些文件不用同步与上传，如数据文件，.pyc文件</span></div><div class="line">  ├── *****.jpg     <span class="comment">#截图文件，三幅图分别为mysql中三张表的截图</span></div><div class="line">  └── <span class="keyword">command</span>.<span class="title">py</span>    #手动添加的文件，为了项目运行的方便</div></pre></td></tr></table></figure>
<ul>
<li>详细源码:  <a href="https://github.com/ryderchan/byrbbs" target="_blank" rel="external">byrbbs</a></li>
</ul>
<h3 id="关键点分析"><a href="#关键点分析" class="headerlink" title="关键点分析"></a>关键点分析</h3><h4 id="模拟登陆与cookie传递"><a href="#模拟登陆与cookie传递" class="headerlink" title="模拟登陆与cookie传递"></a>模拟登陆与cookie传递</h4><figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> [scrapy.FormRequest(<span class="string">"http://bbs.byr.cn/user/ajax_login.json"</span>,</div><div class="line">                                   formdata=LOGIN_FORMDATA,</div><div class="line">                                   meta=&#123;<span class="string">'cookiejar'</span>: <span class="number">1</span>&#125;,</div><div class="line">                                   headers=HEADERS,</div><div class="line">                                   callback=self.logged_in)]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">logged_in</span><span class="params">(self, response)</span>:</span></div><div class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> self.start_urls:</div><div class="line">            item = ByrSectionItem()</div><div class="line">            num = int(url[<span class="number">-1</span>])</div><div class="line">            item[<span class="string">'top_section_num'</span>] = num + <span class="number">1</span>  <span class="comment"># 使存储的类别号从1开始</span></div><div class="line">            item[<span class="string">'top_section_name'</span>] = self.top_section_name[num]</div><div class="line">            <span class="keyword">yield</span> scrapy.Request(url, meta=&#123;<span class="string">'cookiejar'</span>: response.meta[<span class="string">'cookiejar'</span>],<span class="string">'item'</span>:item&#125;, headers=HEADERS, callback=self.parse)</div></pre></td></tr></table></figure>
<p>在scrapy文档中也写有这种方式登陆，将登陆数据，headers等信息传给FormRequest。后续cookie的传递与logged_in函数中的方法一致，通过meta中的cookiejar，而值传递通过其中的item。</p>
<h4 id="文章的处理"><a href="#文章的处理" class="headerlink" title="文章的处理"></a>文章的处理</h4><figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 处理列表，翻页问题</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_article_list_pre</span><span class="params">(self, response)</span>:</span></div><div class="line">        page_list_num = response.xpath(<span class="string">'//*[@class="t-pre-bottom"]/div[1]/ul/li[1]/i/text()'</span>).extract()[<span class="number">0</span>]</div><div class="line">        total_num = int(page_list_num)/self.article_per_list+<span class="number">1</span>  <span class="comment">#页数从1到total_num</span></div><div class="line">        first_list = response._get_url()</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(<span class="number">1</span>,total_num+<span class="number">1</span>):</div><div class="line">            crawl_list_url = first_list+<span class="string">'?p='</span>+str(i)</div><div class="line">            <span class="keyword">yield</span> scrapy.Request(crawl_list_url, meta=&#123;<span class="string">'cookiejar'</span>: response.meta[<span class="string">'cookiejar'</span>],<span class="string">'item'</span>:response.meta[<span class="string">'item'</span>]&#125;, headers=HEADERS,callback=self.parse_article_list)</div><div class="line"></div><div class="line">    <span class="comment"># 处理列表，获取列表上的每条文章信息与文章链接</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_article_list</span><span class="params">(self, response)</span>:</span></div><div class="line">        <span class="comment"># print "parse_article_list "+response._get_url()</span></div><div class="line">        section_name = response.meta[<span class="string">'item'</span>][<span class="string">'section_name'</span>]</div><div class="line">        sel_article = response.xpath(<span class="string">'//*[@class="b-content"]/table/tbody/tr'</span>)</div><div class="line">        article_url = sel_article.xpath(<span class="string">'td[2]/a/@href'</span>).extract()</div><div class="line">        article_title = sel_article.xpath(<span class="string">'td[2]/a/text()'</span>).extract()</div><div class="line">        article_createtime = sel_article.xpath(<span class="string">'td[3]/text()'</span>).extract()</div><div class="line">        article_author = sel_article.xpath(<span class="string">'td[4]/a/text()'</span>).extract()</div><div class="line">        article_comment = sel_article.xpath(<span class="string">'td[5]/text()'</span>).extract()</div><div class="line"></div><div class="line">        <span class="comment"># 处理列表的每一行，即每一篇文章的信息，存入item</span></div><div class="line">        <span class="keyword">for</span> index, url <span class="keyword">in</span> enumerate(article_url):</div><div class="line">            item = ByrArticleItem()</div><div class="line">            item[<span class="string">'section_name'</span>] = section_name</div><div class="line">            item[<span class="string">'article_title'</span>] = article_title[index]</div><div class="line">            item[<span class="string">'article_url'</span>] = response.urljoin(article_url[index])</div><div class="line">            item[<span class="string">'article_createtime'</span>] = article_createtime[index]</div><div class="line">            item[<span class="string">'article_author'</span>] = article_author[index]</div><div class="line">            item[<span class="string">'article_comment'</span>] = article_comment[index]</div><div class="line">            <span class="keyword">yield</span> scrapy.Request(item[<span class="string">'article_url'</span>], meta=&#123;<span class="string">'cookiejar'</span>: response.meta[<span class="string">'cookiejar'</span>],<span class="string">'item'</span>: item&#125;, headers=HEADERS,callback=self.parse_article_content)</div><div class="line"></div><div class="line">    <span class="comment"># 处理文章主体内容</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_article_content</span><span class="params">(self, response)</span>:</span></div><div class="line">        article = response.xpath(<span class="string">'//div[3]/div[1]/table/tr[2]/td[2]/div[1]'</span>).extract()[<span class="number">0</span>]</div><div class="line">        article = re.sub(<span class="string">'&lt;/?(font|div).*?&gt;'</span>, <span class="string">''</span>, article)</div><div class="line">        article = re.sub(<span class="string">'&lt;br&gt;'</span>, <span class="string">'\n'</span>, article)</div><div class="line">        item = response.meta[<span class="string">'item'</span>]</div><div class="line">        item[<span class="string">'article_content'</span>] = article</div><div class="line">        <span class="keyword">yield</span> item</div></pre></td></tr></table></figure>
<h4 id="MySQLdb的使用"><a href="#MySQLdb的使用" class="headerlink" title="MySQLdb的使用"></a>MySQLdb的使用</h4><figure class="highlight python"><table><tr><td class="code"><pre><div class="line">DB_CONFIG = &#123;<span class="string">'host'</span>: <span class="string">'your_mysql_ip'</span>, <span class="string">'user'</span>:<span class="string">'your_mysql_username'</span>, <span class="string">'passwd'</span>:<span class="string">'your_mysql_password'</span>, <span class="string">'db'</span>:<span class="string">'your_database_name'</span>, <span class="string">'port'</span>: <span class="number">3306</span>, <span class="string">'charset'</span>: <span class="string">'utf8'</span>&#125;</div><div class="line">con = MySQLdb.connect(**DB_CONFIG)</div><div class="line">cur = con.cursor()</div><div class="line">sql = <span class="string">'insert into section(section_url,section_name) values(%s,%s)'</span></div><div class="line">values = (item[<span class="string">'section_url'</span>], item[<span class="string">'section_name'</span>])</div><div class="line">cur.execute(sql, values)  <span class="comment"># second parameter must be iterabale</span></div><div class="line">con.commit()</div><div class="line">cur.close()</div><div class="line">con.close()</div></pre></td></tr></table></figure>
<h4 id="使用装饰器，为不同的item指定pipeline"><a href="#使用装饰器，为不同的item指定pipeline" class="headerlink" title="使用装饰器，为不同的item指定pipeline"></a>使用装饰器，为不同的item指定pipeline</h4><p>spider爬取完数据并生成了item，就会传出给pipeline。当有多个爬虫时，就会有多个item，多个pipeline，而所有的item都会按照settings.py文件中设定的顺序依次经过每个pipeline处理。如果你不想让item经过所有的pipeline处理，就需要为item进行指定pipeline操作。这种类似于权限检查的功能可以用装饰器轻松完成。由于我的一个爬虫只对应一类item，所以我的标记是存在了spider上，当然也可以存在item上。</p>
<p>(1) settings.py中启用pipeline</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line">ITEM_PIPELINES = &#123;</div><div class="line">    <span class="string">'byrbbs.pipelines.ByrSectionPipeline'</span>: <span class="number">300</span>,</div><div class="line">    <span class="string">'byrbbs.pipelines.ByrArticlePipeline'</span>: <span class="number">400</span>,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>(2) spider中指定此爬虫后续想要使用的pipeline，进行标记。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="comment"># byr_section.py file</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByrSectionSpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    pipeline = [<span class="string">'ByrSectionPipeline'</span>]</div><div class="line">    <span class="comment"># other code</span></div><div class="line"> </div><div class="line"><span class="comment"># byr_article.py file</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByrArticleSpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    pipeline = [<span class="string">'ByrArticlePipeline'</span>]</div><div class="line">    <span class="comment"># other code</span></div></pre></td></tr></table></figure>
<p>(3) 装饰器，通过spider上的标记完成检测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="comment"># pipelines.py file</span></div><div class="line"><span class="keyword">import</span> functools</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_pipline</span><span class="params">(func)</span>:</span></div><div class="line"><span class="meta">    @functools.wraps(func)</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="keyword">if</span> self.__class__.__name__ <span class="keyword">in</span> spider.pipeline:</div><div class="line">            <span class="keyword">return</span> func(self, item, spider)</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> item</div><div class="line">    <span class="keyword">return</span> wrapper</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByrSectionPipeline</span><span class="params">(object)</span>:</span></div><div class="line"><span class="meta">    @check_pipline</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="comment"># balabala</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ByrArticlePipeline</span><span class="params">(object)</span>:</span></div><div class="line"><span class="meta">    @check_pipline</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="comment"># balabala</span></div></pre></td></tr></table></figure>
<h4 id="LOG的设置"><a href="#LOG的设置" class="headerlink" title="LOG的设置"></a>LOG的设置</h4><p>可以在运行shell指令时添加附加设置，但我更习惯在settings.py中写清楚：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="comment"># settings.py file</span></div><div class="line"><span class="comment">#LOG_ENABLED = False  #是否启用LOG，默认启用</span></div><div class="line">LOG_LEVEL = <span class="string">"INFO"</span>    <span class="comment">#LOG等级，由高到低依次为CRITICAL,ERROR,WARNING,INFO,DEBUG，默认为DEBUG</span></div><div class="line">LOG_FILE = <span class="string">"log_file.txt"</span> <span class="comment">#LOG文件，不指定则不生成，LOG信息显示在运行窗口中</span></div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># shell command</div><div class="line">--logfile &quot;log_file.txt&quot;         #日志文件        </div><div class="line">--loglevel &quot;INFO&quot; or -L &quot;INFO&quot;   #日志等级</div><div class="line">--nolog                          #禁用日志</div></pre></td></tr></table></figure>
<p>在代码中添加日志消息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="keyword">import</span> logging</div><div class="line">logging.warning(<span class="string">"This is a warning"</span>)</div></pre></td></tr></table></figure>
<p>在spider中添加日志消息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(scrapy.Spider)</span>:</span></div><div class="line">    name = <span class="string">'myspider'</span></div><div class="line">    start_urls = [<span class="string">'http://scrapinghub.com'</span>]</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></div><div class="line">        self.logger.info(<span class="string">'Parse function called on %s'</span>, response.url)</div></pre></td></tr></table></figure>
<h2 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h2><p>section table</p>
<p><img src="/img/bbsSpider/section.jpg" width="900" height="900" align="center"></p>
<p>articleinfo table</p>
<p><img src="/img/bbsSpider/articleinfo.jpg" width="900" height="900" align="center"></p>
<p>articlebody table</p>
<p><img src="/img/bbsSpider/articlebody.jpg" width="900" height="900" align="center"></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/qrcode/wechatpay.png" alt="Ryder Chan WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/qrcode/alipay.png" alt="Ryder Chan Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>
	
	<div>
	  
		
<div style="text-align:center;color: #ccc;font-size:14px;">------ 本文结束 ------</div>

      
	</div>
	
    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/scrapy/" rel="tag">#scrapy</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/01/26/hexo小技巧-首页显示文章摘要及图片/" rel="next" title="hexo小技巧-首页显示文章摘要及图片">
                <i class="fa fa-chevron-left"></i> hexo小技巧-首页显示文章摘要及图片
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/02/07/java实现多线程的两种方式/" rel="prev" title="java实现多线程的两种方式">
                java实现多线程的两种方式 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/"
           data-title="scrapy:爬取北邮人论坛所有帖的基本信息及正文" data-url="http://yoursite.com/2017/01/31/scrapy爬取北邮人论坛所有帖的基本信息及正文/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Ryder Chan" />
          <p class="site-author-name" itemprop="name">Ryder Chan</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">10</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ryderchan" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#功能"><span class="nav-number">1.</span> <span class="nav-text">功能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#环境与工具"><span class="nav-number">2.</span> <span class="nav-text">环境与工具</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#scrapy基本原理"><span class="nav-number">3.</span> <span class="nav-text">scrapy基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#关键组件"><span class="nav-number">3.1.</span> <span class="nav-text">关键组件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Scrapy-Engine"><span class="nav-number">3.1.1.</span> <span class="nav-text">Scrapy Engine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scheduler"><span class="nav-number">3.1.2.</span> <span class="nav-text">Scheduler</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Downloader"><span class="nav-number">3.1.3.</span> <span class="nav-text">Downloader</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spiders"><span class="nav-number">3.1.4.</span> <span class="nav-text">Spiders</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Item-Pipeline"><span class="nav-number">3.1.5.</span> <span class="nav-text">Item Pipeline</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Downloader-middlewares（下载器中间件）"><span class="nav-number">3.1.6.</span> <span class="nav-text">Downloader middlewares（下载器中间件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spider-middlewares（spider中间件）"><span class="nav-number">3.1.7.</span> <span class="nav-text">Spider middlewares（spider中间件）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Scheduler-middlewares（调度中间件）"><span class="nav-number">3.1.8.</span> <span class="nav-text">Scheduler middlewares（调度中间件）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网站分析"><span class="nav-number">4.</span> <span class="nav-text">网站分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#模拟登陆"><span class="nav-number">4.1.</span> <span class="nav-text">模拟登陆</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#传递cookie"><span class="nav-number">4.2.</span> <span class="nav-text">传递cookie</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#板块相关文件与逻辑分析"><span class="nav-number">4.3.</span> <span class="nav-text">板块相关文件与逻辑分析</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正式开始"><span class="nav-number">5.</span> <span class="nav-text">正式开始</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#新建项目与数据库"><span class="nav-number">5.1.</span> <span class="nav-text">新建项目与数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用scrapy-shell创建项目及其他常用命令"><span class="nav-number">5.1.1.</span> <span class="nav-text">使用scrapy shell创建项目及其他常用命令</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建数据库表格"><span class="nav-number">5.1.2.</span> <span class="nav-text">创建数据库表格</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码分析"><span class="nav-number">5.2.</span> <span class="nav-text">代码分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#文件目录结构"><span class="nav-number">5.2.1.</span> <span class="nav-text">文件目录结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#关键点分析"><span class="nav-number">5.2.2.</span> <span class="nav-text">关键点分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模拟登陆与cookie传递"><span class="nav-number">5.2.2.1.</span> <span class="nav-text">模拟登陆与cookie传递</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#文章的处理"><span class="nav-number">5.2.2.2.</span> <span class="nav-text">文章的处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MySQLdb的使用"><span class="nav-number">5.2.2.3.</span> <span class="nav-text">MySQLdb的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用装饰器，为不同的item指定pipeline"><span class="nav-number">5.2.2.4.</span> <span class="nav-text">使用装饰器，为不同的item指定pipeline</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LOG的设置"><span class="nav-number">5.2.2.5.</span> <span class="nav-text">LOG的设置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#执行结果"><span class="nav-number">5.3.</span> <span class="nav-text">执行结果</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ryder Chan</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"chenxiaoyu"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
